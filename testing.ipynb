{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All imports in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import model_from_json\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignoring warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading testing dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('corpora/x_test.csv')\n",
    "y_test = pd.read_csv('corpora/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing the type column values with integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test['type'].replace({\n",
    "    'CASH_OUT' : 1,\n",
    "    'PAYMENT'  : 2,\n",
    "    'CASH_IN'  : 3,\n",
    "    'TRANSFER' : 4,\n",
    "    'DEBIT'    : 5\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the nameOrig and nameDest into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x_test.index:\n",
    "    nameOrig = x_test.at[i, 'nameOrig']\n",
    "    nameOrigP = '0' + nameOrig[1:]\n",
    "    x_test.loc[i, 'nameOrig'] = nameOrigP \n",
    "    nameDest = x_test.at[i, 'nameDest']\n",
    "    if nameDest[0] == 'C':\n",
    "        nameDestP = '0' + nameDest[1:]\n",
    "        x_test.loc[i, 'nameDest'] = nameDestP\n",
    "    elif nameDest[0] == 'M':\n",
    "        nameDestP = '1' + nameDest[1:]\n",
    "        x_test.loc[i, 'nameDest'] = nameDestP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type casting all the columns to float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step              float64\n",
       "type              float64\n",
       "amount            float64\n",
       "nameOrig          float64\n",
       "oldbalanceOrg     float64\n",
       "newbalanceOrig    float64\n",
       "nameDest          float64\n",
       "oldbalanceDest    float64\n",
       "newbalanceDest    float64\n",
       "isFlaggedFraud    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.astype('float64').dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling all the columns using the StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler = StandardScaler()\n",
    "columns_to_scale = [\n",
    "    'step',\n",
    "    'amount',\n",
    "    'nameOrig',\n",
    "    'oldbalanceOrg',\n",
    "    'newbalanceOrig',\n",
    "    'nameDest',\n",
    "    'oldbalanceDest', \n",
    "    'newbalanceDest'\n",
    "]\n",
    "x_test[columns_to_scale] = standardScaler.fit_transform(x_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(results, y_test):\n",
    "    matrix = [[0, 0], [0, 0]]\n",
    "    actual_yes, actual_no, predicted_yes = 0, 0, 0\n",
    "    for i in y_test.index:\n",
    "        if y_test.at[i, 'isFraud'] == 1.0:\n",
    "            actual_yes += 1\n",
    "        elif y_test.at[i, 'isFraud'] == 0.0:\n",
    "            actual_no += 1\n",
    "        if results[i] == 1.0:\n",
    "            predicted_yes += 1\n",
    "        matrix[int(y_test.at[i, 'isFraud'])][int(results[i])] += 1\n",
    "    TP = matrix[1][1]\n",
    "    TN = matrix[0][0]\n",
    "    FP = matrix[0][1]\n",
    "    FN = matrix[1][0]\n",
    "    total = len(results)\n",
    "    accuracy = (TP + TN) / total\n",
    "    misclassfication = (FP + FN) / total\n",
    "    recall = TP / actual_yes\n",
    "    specificity = TN / actual_no\n",
    "    precision = TP / predicted_yes\n",
    "    f_score = 2 * ((recall * precision) / (recall + precision))\n",
    "    print('Confusion Matrix: ', matrix)\n",
    "    print('Accuracy: ' + str(math.floor(accuracy * 100)) + '%')    \n",
    "    print('Misclassfication Rate: ' + str(round(misclassfication * 100, 2)) + '%')\n",
    "    print('True Positive Rate (Recall): ' + str(math.floor(recall * 100)) + '%')\n",
    "    print('True Negative Rate (Specificity): ' + str(math.floor(specificity * 100)) + '%')\n",
    "    print('Precision: ' + str(math.floor(precision * 100)) + '%')\n",
    "    print('F1 Score: ' + str(math.floor(f_score * 100)) + '%')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[6591, 4], [49, 333]]\n",
      "Accuracy: 99%\n",
      "Misclassfication Rate: 0.76%\n",
      "True Positive Rate (Recall): 87%\n",
      "True Negative Rate (Specificity): 99%\n",
      "Precision: 98%\n",
      "F1 Score: 92%\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = pickle.load(open('models/knn_classifier.sav', 'rb'))\n",
    "results = knn_classifier.predict(x_test)\n",
    "evaluation_metrics(results, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[6595, 0], [43, 339]]\n",
      "Accuracy: 99%\n",
      "Misclassfication Rate: 0.62%\n",
      "True Positive Rate (Recall): 88%\n",
      "True Negative Rate (Specificity): 100%\n",
      "Precision: 100%\n",
      "F1 Score: 94%\n"
     ]
    }
   ],
   "source": [
    "svc_classifier = pickle.load(open('models/svc_classifier.sav', 'rb'))\n",
    "results = svc_classifier.predict(x_test)\n",
    "evaluation_metrics(results, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[6594, 1], [30, 352]]\n",
      "Accuracy: 99%\n",
      "Misclassfication Rate: 0.44%\n",
      "True Positive Rate (Recall): 92%\n",
      "True Negative Rate (Specificity): 99%\n",
      "Precision: 99%\n",
      "F1 Score: 95%\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = pickle.load(open('models/dt_classifier.sav', 'rb'))\n",
    "results = dt_classifier.predict(x_test)\n",
    "evaluation_metrics(results, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_model():\n",
    "    json_file = open('models/neural_network.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights('models/neural_network.h5') \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    json_file.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[6594, 1], [30, 352]]\n",
      "Accuracy: 99%\n",
      "Misclassfication Rate: 0.44%\n",
      "True Positive Rate (Recall): 92%\n",
      "True Negative Rate (Specificity): 99%\n",
      "Precision: 99%\n",
      "F1 Score: 95%\n"
     ]
    }
   ],
   "source": [
    "x_test = pd.DataFrame(x_test).to_numpy()\n",
    "model = get_nn_model()\n",
    "results = model.predict(x_test, batch_size = 200)\n",
    "nn_results = []\n",
    "for result in results:\n",
    "    if result[0] < 0.5:\n",
    "        nn_results.append(0)\n",
    "    else:\n",
    "        nn_results.append(1)\n",
    "evaluation_metrics(nn_results, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dw-env",
   "language": "python",
   "name": "dw-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
